{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Main PyEPO\n",
    "This notebook uses our classes in close connection with the PyEPO library and follows their tutorial in creating a shortest path optnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to the path\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"../..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "We start with defining an optimization problem with an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy and ShortestPathGrb class\n",
    "import numpy as np\n",
    "from src.models.ShortestPathGrb import shortestPathGrb\n",
    "from src.models.ShortestPathGrid import ShortestPathGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "m, n = (5, 5)\n",
    "np.random.seed(42)  # for reproducibility\n",
    "\n",
    "# Create grid instance\n",
    "grid = ShortestPathGrid(m, n)\n",
    "\n",
    "# Create a opt_model instance\n",
    "opt_model = shortestPathGrb(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random cost array for the grid\n",
    "cost = np.arange((m-1)*n + m*(n-1))\n",
    "np.random.shuffle(cost)\n",
    "\n",
    "# Set the cost for the grid (Optionally specify the source and target nodes)\n",
    "opt_model.setObj(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve shortest path problem\n",
    "path, obj = opt_model.solve(versatile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "We use PyEPO to generate data for the shortest path problem and use its ``optDataset`` class for data storage and loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyepo\n",
    "\n",
    "# Set parameters for data generation\n",
    "num_train_data = 1000 # number of training data\n",
    "num_test_data = 1000 # number of test data\n",
    "num_feat = 5 # size of feature\n",
    "deg = 4 # polynomial degree\n",
    "e = 0.5 # noise width\n",
    "\n",
    "# Generate data for shortest path problem\n",
    "feats, costs = pyepo.data.shortestpath.genData(\n",
    "    num_train_data+num_test_data, \n",
    "    num_feat, \n",
    "    (m,n), \n",
    "    deg=deg, \n",
    "    noise_width=e, \n",
    "    seed=135\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, c_train, c_test = train_test_split(\n",
    "    feats, \n",
    "    costs, \n",
    "    test_size=num_test_data, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets for training and testing\n",
    "dataset_train = pyepo.data.dataset.optDataset(opt_model, x_train, c_train)\n",
    "dataset_test = pyepo.data.dataset.optDataset(opt_model, x_test, c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap dataset into PyTorch DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 32\n",
    "loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Training and Testing\n",
    "We will now create a predictive model. Then we train and test it with the artificial data created in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.LinearRegression import LinearRegression\n",
    "\n",
    "# Instantiate linear regression model\n",
    "model = LinearRegression(num_feat=num_feat, num_edges=opt_model.num_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init SPO+ loss\n",
    "spop = pyepo.func.SPOPlus(opt_model, processes=1)\n",
    "\n",
    "# Init optimizer\n",
    "from torch import optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Train SPO+ loss\n",
    "We will now train the model with SPO+ loss and visualize the learning curves. Note that we do not have to instantiate the linear regression in this instance as it has already been instantiated previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.trainer import Trainer\n",
    "\n",
    "# Set the number of epochs for training\n",
    "epochs = 5\n",
    "\n",
    "# Create a trainer instance\n",
    "trainer = Trainer(pred_model=model, \n",
    "                  opt_model=opt_model, \n",
    "                  optimizer=optimizer, \n",
    "                  loss_fn=spop\n",
    "                )\n",
    "\n",
    "train_loss_log, train_regret_log, test_loss_log, test_regret_log = trainer.fit(loader_train, loader_test, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer.vis_learning_curve(\n",
    "    trainer,\n",
    "    train_loss_log,\n",
    "    train_regret_log,\n",
    "    test_loss_log,\n",
    "    test_regret_log\n",
    ")\n",
    "\n",
    "print(\"Final regret on test set: \", test_regret_log[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Differentiable Black Box Trainer\n",
    "We will now train the Black Box trainer to compare the different performances. Note that the best comparison is the regret, as it is calculated independent of the chosen loss model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate new linear regression model\n",
    "model = LinearRegression(num_feat=num_feat, num_edges=opt_model.num_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init dbb solver\n",
    "dbb = pyepo.func.blackboxOpt(opt_model, lambd=20)\n",
    "# Set loss\n",
    "from torch import nn\n",
    "l1 = nn.L1Loss()\n",
    "\n",
    "# Loss function\n",
    "def dbbl1(cp, c, z):\n",
    "    # Black-box optimizer\n",
    "    wp = dbb(cp)\n",
    "    # Objective value\n",
    "    zp = (wp * c).sum(1).view(-1, 1)\n",
    "    # Loss\n",
    "    loss = l1(zp, z)\n",
    "    return loss\n",
    "\n",
    "# Init optimizer\n",
    "from torch import optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a trainer instance\n",
    "trainer = Trainer(pred_model=model, \n",
    "                  opt_model=opt_model, \n",
    "                  optimizer=optimizer, \n",
    "                  loss_fn=dbbl1, \n",
    "                  method_name=\"dbb\"\n",
    "               )\n",
    "\n",
    "# Train the model with DBB loss\n",
    "train_loss_log, train_regret_log, test_loss_log, test_regret_log = trainer.fit(loader_train, loader_test, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.vis_learning_curve(\n",
    "    trainer,\n",
    "    train_loss_log,\n",
    "    train_regret_log,\n",
    "    test_loss_log,\n",
    "    test_regret_log\n",
    ")\n",
    "\n",
    "print(\"Final regret on test set: \", test_regret_log[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
